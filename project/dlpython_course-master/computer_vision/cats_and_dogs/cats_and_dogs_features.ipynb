{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Распознавание собак и кошек на изображениях с помощью признаков, извлеченных предварительно обученной нейронной сетью VGG16\n",
    "\n",
    "**Источник данных** - соревнования Kaggle [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats/data).\n",
    "\n",
    "Для распознавания используется предварительно обученная сверточная нейронная сеть VGG16.\n",
    "\n",
    "Перед использованием необходимо скачать и подготовить данные для обучения, проверки и тестирования. Можно использовать пример в ноутбуке data_preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sozyk\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.python.keras.applications import VGG16\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Каталог с данными для обучения\n",
    "train_dir = 'train'\n",
    "# Каталог с данными для проверки\n",
    "val_dir = 'val'\n",
    "# Каталог с данными для тестирования\n",
    "test_dir = 'test'\n",
    "# Размеры изображения\n",
    "img_width, img_height = 150, 150\n",
    "# Размерность тензора на основе изображения для входных данных в нейронную сеть\n",
    "# backend Tensorflow, channels_last\n",
    "input_shape = (img_width, img_height, 3)\n",
    "# Размер мини-выборки\n",
    "batch_size = 10\n",
    "# Количество изображений для обучения\n",
    "nb_train_samples = 17500\n",
    "# Количество изображений для проверки\n",
    "nb_validation_samples = 3750\n",
    "# Количество изображений для тестирования\n",
    "nb_test_samples = 3750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем предварительно обученную нейронную сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_net = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Готовим генераторы данных для извлечения признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3750 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3750 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерируем признаки и сохраняем их в файлы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки для изображений из набора данных для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = vgg16_net.predict_generator(\n",
    "        train_generator, nb_train_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open('features_train.npy', 'wb'), features_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки для изображений из проверочного набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_val = vgg16_net.predict_generator(\n",
    "        val_generator, nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open('features_val.npy', 'wb'), features_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки для изображений из тестового набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = vgg16_net.predict_generator(\n",
    "        test_generator, nb_test_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open('features_test.npy', 'wb'), features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерируем метки для трех наборов данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train =  np.array(\n",
    "        [0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val =  np.array(\n",
    "        [0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test =  np.array(\n",
    "        [0] * (nb_test_samples // 2) + [1] * (nb_test_samples // 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем признаки из файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = np.load(open('features_train.npy', 'rb'))\n",
    "features_val = np.load(open('features_val.npy', 'rb'))\n",
    "features_test = np.load(open('features_test.npy', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем полносвязную сверточную нейронную сеть для классификации извлеченных из изображения признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=features_train.shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель на признаках, которые извлекли из изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17500 samples, validate on 3750 samples\n",
      "Epoch 1/15\n",
      " - 5s - loss: 0.3228 - acc: 0.8636 - val_loss: 0.2185 - val_acc: 0.9109\n",
      "Epoch 2/15\n",
      " - 4s - loss: 0.2234 - acc: 0.9053 - val_loss: 0.2346 - val_acc: 0.9019\n",
      "Epoch 3/15\n",
      " - 4s - loss: 0.1967 - acc: 0.9171 - val_loss: 0.2090 - val_acc: 0.9157\n",
      "Epoch 4/15\n",
      " - 4s - loss: 0.1881 - acc: 0.9207 - val_loss: 0.2628 - val_acc: 0.8880\n",
      "Epoch 5/15\n",
      " - 4s - loss: 0.1697 - acc: 0.9304 - val_loss: 0.2085 - val_acc: 0.9152\n",
      "Epoch 6/15\n",
      " - 4s - loss: 0.1643 - acc: 0.9322 - val_loss: 0.2128 - val_acc: 0.9147\n",
      "Epoch 7/15\n",
      " - 4s - loss: 0.1476 - acc: 0.9402 - val_loss: 0.2113 - val_acc: 0.9189\n",
      "Epoch 8/15\n",
      " - 4s - loss: 0.1361 - acc: 0.9432 - val_loss: 0.2114 - val_acc: 0.9165\n",
      "Epoch 9/15\n",
      " - 4s - loss: 0.1253 - acc: 0.9488 - val_loss: 0.2218 - val_acc: 0.9187\n",
      "Epoch 10/15\n",
      " - 4s - loss: 0.1125 - acc: 0.9538 - val_loss: 0.2280 - val_acc: 0.9205\n",
      "Epoch 11/15\n",
      " - 4s - loss: 0.1080 - acc: 0.9575 - val_loss: 0.2328 - val_acc: 0.9147\n",
      "Epoch 12/15\n",
      " - 4s - loss: 0.0941 - acc: 0.9611 - val_loss: 0.2330 - val_acc: 0.9208\n",
      "Epoch 13/15\n",
      " - 4s - loss: 0.0943 - acc: 0.9618 - val_loss: 0.2332 - val_acc: 0.9197\n",
      "Epoch 14/15\n",
      " - 4s - loss: 0.0774 - acc: 0.9676 - val_loss: 0.2623 - val_acc: 0.9173\n",
      "Epoch 15/15\n",
      " - 4s - loss: 0.0823 - acc: 0.9669 - val_loss: 0.2431 - val_acc: 0.9205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1cf80163898>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features_train, labels_train,\n",
    "              epochs=15,\n",
    "              batch_size=64,\n",
    "              validation_data=(features_val, labels_val), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750/3750 [==============================] - 0s 78us/step\n",
      "Аккуратность на тестовых данных: 91.25%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(features_test, labels_test, verbose=1)\n",
    "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
